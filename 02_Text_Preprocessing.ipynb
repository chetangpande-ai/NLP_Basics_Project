{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Text Preprocessing\n",
    "\n",
    "In this notebook, we will explore fundamental text preprocessing techniques:\n",
    "1. **Tokenization**: Breaking text into words or sentences.\n",
    "2. **Stopword Removal**: Removing common words that add little meaning.\n",
    "3. **Stemming**: Reducing words to their root form (heuristic).\n",
    "4. **Lemmatization**: Reducing words to their base form (linguistic)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "# Load spaCy model\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tokenization\n",
    "Splitting text into smaller units (tokens)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Natural Language Processing is fascinating. It enables computers to understand human language!\"\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentences = sent_tokenize(text)\n",
    "print(\"Sentences:\", sentences)\n",
    "\n",
    "# Word Tokenization\n",
    "words = word_tokenize(text)\n",
    "print(\"\\nWords:\", words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stopword Removal\n",
    "Removing common words like 'is', 'the', 'to'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "\n",
    "print(\"Original:\", words)\n",
    "print(\"Filtered:\", filtered_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stemming\n",
    "Chopping off suffixes (e.g., 'running' -> 'run'). Fast but crude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "words_to_stem = [\"running\", \"runs\", \"ran\", \"easily\", \"fairly\"]\n",
    "stemmed_words = [stemmer.stem(word) for word in words_to_stem]\n",
    "\n",
    "for original, stemmed in zip(words_to_stem, stemmed_words):\n",
    "    print(f\"{original} -> {stemmed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Lemmatization\n",
    "Using vocabulary and morphological analysis to return the base form (lemma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "print(\"NLTK Lemmatization:\")\n",
    "print(f\"better -> {lemmatizer.lemmatize('better', pos='a')} (adjective)\")\n",
    "print(f\"running -> {lemmatizer.lemmatize('running', pos='v')} (verb)\")\n",
    "\n",
    "print(\"\\nspaCy Lemmatization (Context-aware):\")\n",
    "doc = nlp(\"The striped bats are hanging on their feet for best results.\")\n",
    "for token in doc:\n",
    "    print(f\"{token.text} -> {token.lemma_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
